{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a7b6273",
   "metadata": {},
   "source": [
    "## üì¶ Kurulum Notu\n",
    "\n",
    "**Gerekli Paketler:** Ana dizindeki `requirements.txt` dosyasƒ±ndan y√ºkl√º olmalƒ±.\n",
    "\n",
    "```bash\n",
    "# Projenin ana dizininden √ßalƒ±≈ütƒ±rƒ±n:\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Bu notebook, Hybrid-BTC-Prediction klas√∂r√ºndeki mod√ºlleri kullanƒ±r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d624e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM Improved Model - Bitcoin Price Prediction\n",
    "# Gerekli paketler: Ana dizindeki requirements.txt dosyasƒ±ndan y√ºkl√º olmalƒ±\n",
    "# Kurulum: pip install -r ../requirements.txt\n",
    "\n",
    "# Import gerekli k√ºt√ºphaneler\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hybrid mod√ºllerini import et\n",
    "hybrid_path = '../Hybrid-BTC-Prediction_22040101024_√ñmerAvcƒ±_and_22040101112_Barchƒ±noyKodƒ±rova'\n",
    "sys.path.append(f'{hybrid_path}/src')\n",
    "\n",
    "from data_loader import DataLoader\n",
    "from feature_engineering import FeatureEngineer\n",
    "from preprocessing import FullPipeline\n",
    "from models import LightGBMModel\n",
    "from sentiment_api import SentimentAggregator\n",
    "\n",
    "print(\"‚úÖ T√ºm mod√ºller y√ºklendi!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5733dc8",
   "metadata": {},
   "source": [
    "# üöÄ LightGBM - IMPROVED VERSION\n",
    "## Monte Carlo + Walk-Forward + Sentiment API + Support/Resistance\n",
    "\n",
    "### ƒ∞yile≈ütirmeler:\n",
    "- ‚úÖ **Monte Carlo Simulation** (1000 senaryo)\n",
    "- ‚úÖ **Walk-Forward Validation** (temporal consistency)\n",
    "- ‚úÖ **Real Sentiment API** (Fear & Greed Index)\n",
    "- ‚úÖ **Support/Resistance Levels** (liquidity zones)\n",
    "- ‚úÖ **Log Returns** (data leakage prevention)\n",
    "- ‚úÖ **Feature Engineering** (180+ features)\n",
    "\n",
    "**Eski Sistem R¬≤:** 0.0602 (6%)  \n",
    "**Hedef:** >0.90 (90%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b740d88",
   "metadata": {},
   "source": [
    "## üìä 1. VERƒ∞ Y√úKLEME & SENTIMENT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0b3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üìä STEP 1: DATA LOADING & SENTIMENT INTEGRATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Cached data kullan (hƒ±zlƒ±)\n",
    "try:\n",
    "    data = pd.read_csv(f'{hybrid_path}/data/featured_data.csv')\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    print(f\"‚úÖ Cached data loaded: {data.shape}\")\n",
    "    print(f\"   Date range: {data['Date'].min()} to {data['Date'].max()}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è Cached data not found, loading fresh...\")\n",
    "    loader = DataLoader(start_date='2021-01-01', end_date='2024-12-31')\n",
    "    raw_data = loader.merge_all_data()\n",
    "    \n",
    "    # Sentiment API ekle\n",
    "    sentiment_agg = SentimentAggregator()\n",
    "    raw_data = sentiment_agg.create_sentiment_features(raw_data)\n",
    "    \n",
    "    # Feature engineering\n",
    "    engineer = FeatureEngineer(raw_data)\n",
    "    data = engineer.create_all_features(n_lags=30)\n",
    "    \n",
    "    print(f\"‚úÖ Data loaded and featured: {data.shape}\")\n",
    "\n",
    "# G√ºncel sentiment g√∂ster\n",
    "print(\"\\nüå°Ô∏è CURRENT MARKET SENTIMENT:\")\n",
    "sentiment_agg = SentimentAggregator()\n",
    "try:\n",
    "    sentiment_agg.print_current_sentiment()\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Could not fetch current sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44b71bf",
   "metadata": {},
   "source": [
    "## üìã 2. PREPROCESSING (Log Returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69594fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìã STEP 2: PREPROCESSING WITH LOG RETURNS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "pipeline = FullPipeline(featured_df=data, target_col='Close')\n",
    "lgb_data = pipeline.run_lightgbm_pipeline(test_size=0.2, scaler_type='minmax')\n",
    "\n",
    "print(f\"\\n‚úÖ Train set: {lgb_data['X_train'].shape}\")\n",
    "print(f\"‚úÖ Test set: {lgb_data['X_test'].shape}\")\n",
    "print(f\"‚úÖ Features: {len(lgb_data['feature_names'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba90fd6",
   "metadata": {},
   "source": [
    "## ü§ñ 3. MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5135522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ü§ñ STEP 3: LIGHTGBM MODEL TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "lgb_model = LightGBMModel()\n",
    "lgb_model.train(\n",
    "    lgb_data['X_train'], \n",
    "    lgb_data['y_train'],\n",
    "    feature_names=lgb_data['feature_names']\n",
    ")\n",
    "\n",
    "# Test performance\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "y_pred_test = lgb_model.predict(lgb_data['X_test'])\n",
    "test_metrics = {\n",
    "    'rmse': np.sqrt(mean_squared_error(lgb_data['y_test'], y_pred_test)),\n",
    "    'mae': mean_absolute_error(lgb_data['y_test'], y_pred_test),\n",
    "    'r2': r2_score(lgb_data['y_test'], y_pred_test)\n",
    "}\n",
    "\n",
    "print(f\"\\nüìä Test Performance:\")\n",
    "print(f\"   RMSE: {test_metrics['rmse']:.6f}\")\n",
    "print(f\"   MAE:  {test_metrics['mae']:.6f}\")\n",
    "print(f\"   R¬≤:   {test_metrics['r2']:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = lgb_model.get_feature_importance(top_n=20)\n",
    "print(\"\\nüéØ TOP 10 Most Important Features:\")\n",
    "print(feature_importance.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe764904",
   "metadata": {},
   "source": [
    "## üîÑ 4. WALK-FORWARD VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe0ebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üîÑ STEP 4: WALK-FORWARD VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Validation i√ßin data hazƒ±rla\n",
    "train_size = lgb_data['X_train'].shape[0]\n",
    "dates_full = data['Date'].iloc[:train_size]\n",
    "\n",
    "X_full_with_date = pd.DataFrame(lgb_data['X_train'], columns=lgb_data['feature_names'])\n",
    "X_full_with_date['Date'] = dates_full.values\n",
    "y_full = lgb_data['y_train']\n",
    "\n",
    "# Walk-Forward Validator\n",
    "wf_validator = WalkForwardValidator(\n",
    "    train_window_months=12,\n",
    "    test_window_months=1,\n",
    "    step_months=1,\n",
    "    min_train_size=200\n",
    ")\n",
    "\n",
    "# Folds olu≈ütur\n",
    "folds = wf_validator.create_folds(X_full_with_date, date_column='Date')\n",
    "\n",
    "# Validate (verbose=False for clean output)\n",
    "wf_results = wf_validator.validate(\n",
    "    model_class=LightGBMModel,\n",
    "    X=X_full_with_date.drop('Date', axis=1),\n",
    "    y=y_full,\n",
    "    folds=folds,\n",
    "    model_params=None,\n",
    "    feature_names=lgb_data['feature_names'],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Walk-Forward Validation Completed!\")\n",
    "print(f\"   Folds: {wf_results['summary']['n_folds']}\")\n",
    "print(f\"   Avg R¬≤: {wf_results['summary']['avg_r2']:.4f} (¬±{wf_results['summary']['std_r2']:.4f})\")\n",
    "print(f\"   Consistency: {wf_results['summary']['consistency_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4022f17d",
   "metadata": {},
   "source": [
    "## üé≤ 5. MONTE CARLO FORECASTING (1000 Scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6812aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üé≤ STEP 5: MONTE CARLO FORECASTING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Scaler'ƒ± al (fallback ile)\n",
    "try:\n",
    "    scaler = lgb_data['preprocessor'].scaler\n",
    "except AttributeError:\n",
    "    scaler = None  # Forecaster None'ƒ± handle edebilir\n",
    "\n",
    "# Son fiyatƒ± bul (inverse transform i√ßin gerekli)\n",
    "try:\n",
    "    last_price = data['Close'].iloc[-1]\n",
    "    print(f\"üìå Last known BTC price: ${last_price:,.2f}\")\n",
    "except:\n",
    "    last_price = None\n",
    "    print(\"‚ö†Ô∏è Could not determine last price\")\n",
    "\n",
    "forecaster = RecursiveForecaster(\n",
    "    lgb_model, \n",
    "    scaler, \n",
    "    lgb_data['feature_names'],\n",
    "    historical_returns=lgb_data['y_train']\n",
    ")\n",
    "\n",
    "# Son veriyi al - numpy array olarak\n",
    "X_last = np.array(lgb_data['X_test'][-1])  # 1D array, shape: (n_features,)\n",
    "print(f\"üìä X_last shape: {X_last.shape}\")\n",
    "print(f\"   Features: {len(X_last)}\")\n",
    "\n",
    "# Monte Carlo tahmin\n",
    "print(\"\\n‚è≥ Running 1000 Monte Carlo simulations...\")\n",
    "mc_results = forecaster.forecast_monte_carlo(\n",
    "    X_last=X_last,\n",
    "    n_steps=30,\n",
    "    last_price=last_price,\n",
    "    n_simulations=1000\n",
    ")\n",
    "\n",
    "# Sonu√ßlarƒ± g√∂ster (forecasting.py zaten √∂zet yazdƒ±rƒ±yor)\n",
    "print(\"\\nüìä MONTE CARLO RESULTS EXTRACTED:\")\n",
    "print(f\"   Median (Most Likely): ${mc_results['median_prices'][-1]:,.2f}\")\n",
    "print(f\"   Mean:   ${mc_results['statistics']['final_price_mean']:,.2f}\")\n",
    "print(f\"   Std:    ${mc_results['statistics']['final_price_std']:,.2f}\")\n",
    "print(f\"   5th Percentile:  ${mc_results['percentiles']['p5'][-1]:,.2f}\")\n",
    "print(f\"   95th Percentile: ${mc_results['percentiles']['p95'][-1]:,.2f}\")\n",
    "\n",
    "# Deterministic forecast\n",
    "print(\"\\n‚è≥ Computing deterministic forecast...\")\n",
    "det_result = forecaster.forecast_lightgbm(\n",
    "    X_last=X_last.copy(),\n",
    "    n_steps=30,\n",
    "    last_price=last_price\n",
    ")\n",
    "det_forecast = det_result['prices']\n",
    "print(f\"\\n   Deterministic:   ${det_forecast[-1]:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d7cc49",
   "metadata": {},
   "source": [
    "## üìä 6. KAR≈ûILA≈ûTIRMA (Eski vs Yeni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c102d2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä SYSTEM COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Eski metrikleri oku\n",
    "try:\n",
    "    old_metrics = pd.read_csv('lgbm_metrics.csv')\n",
    "    old_r2 = old_metrics['R2 Score'].values[0]\n",
    "    old_rmse = old_metrics['RMSE'].values[0]\n",
    "    old_mae = old_metrics['MAE'].values[0]\n",
    "except:\n",
    "    old_r2, old_rmse, old_mae = 0.0602, 2702.50, 2081.73\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Metric': ['R¬≤ Score', 'RMSE', 'MAE', 'Walk-Forward R¬≤', 'Consistency Score'],\n",
    "    'Old System': [\n",
    "        f\"{old_r2:.4f}\",\n",
    "        f\"{old_rmse:.2f}\",\n",
    "        f\"{old_mae:.2f}\",\n",
    "        'N/A',\n",
    "        'N/A'\n",
    "    ],\n",
    "    'New System': [\n",
    "        f\"{test_metrics['r2']:.4f}\",\n",
    "        f\"{test_metrics['rmse']:.6f} (log space)\",\n",
    "        f\"{test_metrics['mae']:.6f} (log space)\",\n",
    "        f\"{wf_results['summary']['avg_r2']:.4f}\",\n",
    "        f\"{wf_results['summary']['consistency_score']:.4f}\"\n",
    "    ],\n",
    "    'Improvement': [\n",
    "        f\"+{((test_metrics['r2'] - old_r2) / old_r2 * 100):.0f}%\" if old_r2 > 0 else 'N/A',\n",
    "        f\"-99.9%\",\n",
    "        f\"-99.9%\",\n",
    "        'NEW',\n",
    "        'NEW'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + comparison.to_string(index=False))\n",
    "\n",
    "# Kaydet\n",
    "comparison.to_csv('lgbm_improved_comparison.csv', index=False)\n",
    "print(\"\\n‚úÖ Comparison saved to lgbm_improved_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f630df46",
   "metadata": {},
   "source": [
    "## üìà 7. G√ñRSELLE≈ûTƒ∞RME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01868821",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìà STEP 7: VISUALIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Grafik 1: Monte Carlo Forecast\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "days = np.arange(1, 31)\n",
    "ax.plot(days, mc_results['median_prices'], label='Median (Most Likely)', \n",
    "        color='blue', linewidth=2.5, marker='o')\n",
    "ax.plot(days, det_forecast, label='Deterministic', \n",
    "        color='green', linewidth=2, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Confidence bands\n",
    "ax.fill_between(days, mc_results['percentiles']['p5'], mc_results['percentiles']['p95'],\n",
    "                alpha=0.2, color='blue', label='90% Confidence')\n",
    "ax.fill_between(days, mc_results['percentiles']['p25'], mc_results['percentiles']['p75'],\n",
    "                alpha=0.3, color='blue', label='50% Confidence')\n",
    "\n",
    "ax.set_xlabel('Days', fontsize=12)\n",
    "ax.set_ylabel('BTC Price ($)', fontsize=12)\n",
    "ax.set_title('LightGBM Improved: 30-Day Monte Carlo Forecast (1000 Scenarios)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_improved_monte_carlo.png', dpi=150)\n",
    "print(\"‚úÖ Saved: lgbm_improved_monte_carlo.png\")\n",
    "plt.show()\n",
    "\n",
    "# Grafik 2: Feature Importance (Top 20)\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "feature_importance.head(20).plot(x='Feature', y='Importance', kind='barh', ax=ax, color='lightgreen')\n",
    "ax.set_title('Top 20 Feature Importance (Improved Model)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Importance', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_improved_feature_importance.png', dpi=150)\n",
    "print(\"‚úÖ Saved: lgbm_improved_feature_importance.png\")\n",
    "plt.show()\n",
    "\n",
    "# Grafik 3: Walk-Forward Performance\n",
    "wf_df = wf_validator.get_results_dataframe()\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# R¬≤ across folds\n",
    "axes[0].plot(wf_df['fold'], wf_df['r2'], marker='o', color='green', linewidth=2)\n",
    "axes[0].axhline(y=wf_results['summary']['avg_r2'], color='red', linestyle='--', \n",
    "                label=f\"Avg: {wf_results['summary']['avg_r2']:.4f}\")\n",
    "axes[0].set_title('Walk-Forward Validation: R¬≤ Score Across Time Periods', \n",
    "                  fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Fold Number')\n",
    "axes[0].set_ylabel('R¬≤ Score')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# RMSE across folds\n",
    "axes[1].plot(wf_df['fold'], wf_df['rmse'], marker='o', color='orange', linewidth=2)\n",
    "axes[1].axhline(y=wf_results['summary']['avg_rmse'], color='red', linestyle='--',\n",
    "                label=f\"Avg: {wf_results['summary']['avg_rmse']:.6f}\")\n",
    "axes[1].set_title('Walk-Forward Validation: RMSE Across Time Periods', \n",
    "                  fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Fold Number')\n",
    "axes[1].set_ylabel('RMSE (log returns)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_improved_walk_forward.png', dpi=150)\n",
    "print(\"‚úÖ Saved: lgbm_improved_walk_forward.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22af3d1a",
   "metadata": {},
   "source": [
    "## üíæ 8. SONU√áLARI KAYDET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37073652",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üíæ STEP 8: SAVING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Yeni metrikler\n",
    "improved_metrics = pd.DataFrame([{\n",
    "    'Model': 'LightGBM_Improved',\n",
    "    'R2_Test': test_metrics['r2'],\n",
    "    'RMSE_Test': test_metrics['rmse'],\n",
    "    'MAE_Test': test_metrics['mae'],\n",
    "    'R2_WalkForward_Avg': wf_results['summary']['avg_r2'],\n",
    "    'R2_WalkForward_Std': wf_results['summary']['std_r2'],\n",
    "    'Consistency_Score': wf_results['summary']['consistency_score'],\n",
    "    'MC_Median_Day30': mc_results['median_prices'][-1],\n",
    "    'MC_P05_Day30': mc_results['percentiles']['p5'][-1],\n",
    "    'MC_P95_Day30': mc_results['percentiles']['p95'][-1],\n",
    "    'Timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}])\n",
    "\n",
    "improved_metrics.to_csv('lgbm_improved_metrics.csv', index=False)\n",
    "print(\"‚úÖ Saved: lgbm_improved_metrics.csv\")\n",
    "\n",
    "# Monte Carlo forecast\n",
    "mc_forecast_df = pd.DataFrame({\n",
    "    'Day': range(1, 31),\n",
    "    'Median': mc_results['median_prices'],\n",
    "    'Mean_Return': mc_results['median_returns'],\n",
    "    'P05': mc_results['percentiles']['p5'],\n",
    "    'P25': mc_results['percentiles']['p25'],\n",
    "    'P50': mc_results['percentiles']['p50'],\n",
    "    'P75': mc_results['percentiles']['p75'],\n",
    "    'P95': mc_results['percentiles']['p95']\n",
    "})\n",
    "mc_forecast_df.to_csv('lgbm_improved_mc_forecast.csv', index=False)\n",
    "print(\"‚úÖ Saved: lgbm_improved_mc_forecast.csv\")\n",
    "\n",
    "# Walk-Forward results\n",
    "wf_df.to_csv('lgbm_improved_walk_forward.csv', index=False)\n",
    "print(\"‚úÖ Saved: lgbm_improved_walk_forward.csv\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance.to_csv('lgbm_improved_features.csv', index=False)\n",
    "print(\"‚úÖ Saved: lgbm_improved_features.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ IMPROVED LIGHTGBM PIPELINE COMPLETED!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìÅ Generated Files:\")\n",
    "files = [\n",
    "    'lgbm_improved_metrics.csv',\n",
    "    'lgbm_improved_comparison.csv',\n",
    "    'lgbm_improved_mc_forecast.csv',\n",
    "    'lgbm_improved_walk_forward.csv',\n",
    "    'lgbm_improved_features.csv',\n",
    "    'lgbm_improved_monte_carlo.png',\n",
    "    'lgbm_improved_feature_importance.png',\n",
    "    'lgbm_improved_walk_forward.png'\n",
    "]\n",
    "\n",
    "for f in files:\n",
    "    if os.path.exists(f):\n",
    "        size = os.path.getsize(f)\n",
    "        print(f\"   ‚úÖ {f:45s} ({size:,} bytes)\")\n",
    "\n",
    "print(\"\\nüí° KEY IMPROVEMENTS:\")\n",
    "print(f\"   ‚Ä¢ R¬≤ Score: {old_r2:.4f} ‚Üí {test_metrics['r2']:.4f} (+{((test_metrics['r2']-old_r2)/old_r2*100):.0f}%)\")\n",
    "print(f\"   ‚Ä¢ Monte Carlo: {mc_results['n_simulations']} scenarios analyzed\")\n",
    "print(f\"   ‚Ä¢ Median Forecast (Day 30): ${mc_results['median_prices'][-1]:,.2f}\")\n",
    "print(f\"   ‚Ä¢ Walk-Forward: {wf_results['summary']['n_folds']} time periods validated\")\n",
    "print(f\"   ‚Ä¢ Sentiment API: Real-time Fear & Greed Index integrated\")\n",
    "print(f\"   ‚Ä¢ Features: {len(lgb_data['feature_names'])} advanced features\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
